{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pylab as pl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/all_data.csv\")\n",
    "target = data.iloc[:,85]\n",
    "features = data.iloc[:,1:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD6CAYAAACIyQ0UAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAU9ElEQVR4nO3df5DcdX3H8debuyQbMAg0J1LwOBRGWksUvJFgnI4yE0zBH7E6LZZQZMRUrS3pdKxJyUi0YcBxhsZOdWxKbaGJSEflRhExmQHGEUz0QkLCj2AiROSKJEpjguQSLnn3j92Du8vufr+b/X6/n++P52PmJnv7/e7u67757uu+9/1+vt81dxcAIL+OCx0AANAeRQ0AOUdRA0DOUdQAkHMUNQDkHEUNADnXG2cmM9slab+kw5LG3H0wzVAAgFfEKuqGd7n7r+PMOHv2bB8YGDi2RABQQZs2bfq1u/c1m9ZJUcc2MDCg4eHhNJ4aAErJzH7RalrcfdQuaZ2ZbTKzxcnEAgDEEXeL+h3uPmJmr5G03sy2u/sPJ87QKPDFktTf359wTACorlhb1O4+0vh3t6Q7Jb2tyTyr3X3Q3Qf7+pruZgEAHIPIojazE8xs1vhtSZdIeiTtYACAuji7Pk6VdKeZjc//dXe/J9VUAICXRRa1uz8p6c0ZZAEANJHK8DwUx8DS77WctuumyzJMAqAVTiGvsHYlHWc6gGxQ1BUVt4QpayA8ihqRKGsgLIq6giheoFgoagDIOYoasbAVDoRDUVcMhQsUD0UNADlHUSO2c6+7O3QEoJIo6grpdrfH6GFPKAmATlDUAJBzFDVexrU9gHyiqAEg5yhqTBK1Vc3wPiB7FHVFRBUsuz2A/KKoASDnKGoAyDmKGgByjqLGUTigCOQLRV0BHEgEio2iBoCco6gBIOcoagDIOYoaTUXttx7aPJJREgAUdcUd64HEJXdsSTYIgJYo6pJjKB1QfBQ1AOQcRQ0AOUdRoyVOhAHygaIGgJyjqCus2y1mDlQC2aCoS+zsZRQpUAYUdYmNeegEAJIQu6jNrMfMNpvZXWkGAgBM1skW9bWSHk8rCPLpxBk9oSMAlRerqM3sDEmXSbol3TjIm62fWxA6AlB5cbeoV0n6B0lH0ouCLDFGGiiOyKI2s/dI2u3umyLmW2xmw2Y2vGfPnsQCIt8YogekL84W9TxJ7zOzXZK+IeliM1szdSZ3X+3ug+4+2NfXl3BMdGrO9feEjgAgIZFF7e7L3P0Mdx+QdLmke919UerJ0JV9Bw+HjgAgIYyjBoCc66io3f1+d39PWmGQT/PecEroCEClsUWNSGs/dlHoCEClUdQVxNA8oFgoanSNIXpAuihqAMg5irqE2MIFyoWiBoCco6gBIOcoasTCSBEgHIq6YhbN7Q8dAUCHKOqKWbnwvNARAHSoN3QABLTi1R0+YK0ka3K/a2Dpd7Wr1sG1ulb8tsPXBqqLoi6Zoc0jAV61WXkDSAq7PkpmyR1bQkcAkDCKGgByjqJGbOfoaUkeOgZQORQ1YltfWxY6AlBJFHWFcNIKUEwUNQDkHEWNxAyMHvXh9AASwDhqJISx1EBa2KIuEa5DDZQTRQ0AOUdRoyOLbJ0YSw1ki6JGR1bOuDV0BKByKOqKYAw1UFwUNQDkHEWNRF04+qXQEYDSoaiRINNzmh06BFA6FHVJnL2MMdRAWVHUJTHGiDmgtChqdKymA2IsNZAdihod2167JnQEoFIo6gpYNLc/dAQAXaCoK2DlwvNCRwDQhciiNrOamf3EzB42s0fN7HNZBENxXTH6mdARgFKJcz3qg5IudvcXzGyapB+Z2ffdfUPK2VBIpgc0J3QIoFQii9rdXdILjW+nNb445J8jF96wPnQEACmKtY/azHrMbIuk3ZLWu/vGVFOhI8/tPxQ6AoAUxSpqdz/s7m+RdIakt5nZH02dx8wWm9mwmQ3v2bMn4ZjIm14dEn9YAdnoaNSHu++VdJ+kBU2mrXb3QXcf7OvrSyge8mpn7erQEYDKiDPqo8/MTmrcnilpvqTtKedCQvjIWaD44oz6OE3SrWbWo3qx/4+735VuLCTlKT4wACi8OKM+tko6P4MsAIAmODMRqRgY/e/QEYDSoKiRAhOrFpAc3k0FN7CUDwwAyo6ixjE7R0+LsdRA+ihqHLP1tWWhIwCVQFEDQM5R1CW2izHUQClQ1ACQcxQ1UjMwelvoCEApUNRIiUnqCR0CKAWKusDOYgw1UAkUdYExghmoBooaXVnV+2XxKwNIF0WNrizsfTB0BKD0KOqSWjS3P3QEAAmhqEtq5cLzQkcAkBCKGqm6YvQzoSMAhUdRI0WmBzQndAig8Cjqgppz/T2hIwDICEVdUPsOHg4dAUBGKGp0jQ8QANJFUaNrfIAAkC6KuoROnTU9dAQACaKoS2jjdfNDRwCQIIoaqVt+8KrQEYBCo6iRMtMaZwsf6AZFXUBDm0dCR+iQhQ4AFBpFXUBL7tgSOgKADFHUSMQiWyfGUgPpoKiRiJUzbg0dASgtirpketkdDJQORV0yO2+8LHQEAAmjqJGJOaNfDR0BKCyKGhkw7dOs0CGAwoosajN7nZndZ2aPmdmjZnZtFsHQ3IU3rA8dAUDGemPMMybp7939ITObJWmTma1398dSzoYmntt/KHQEABmL3KJ292fd/aHG7f2SHpd0etrBUDxclxpIR0f7qM1sQNL5kjamkgaFxnWpgXTE2fUhSTKzV0n6lqQl7r6vyfTFkhZLUn9/f2IBK2HFqzuYea2aXzvD62cHrviLhEIByItYW9RmNk31kl7r7t9uNo+7r3b3QXcf7OvrSzIjYuLsQKCc4oz6MEn/Ielxd785/Ugoq7NG+UUCHIs4W9TzJF0p6WIz29L4ujTlXCgdk8ff0wZggsh3jrv/SFxQOBfOHb0ldAQAAXBmYoGMaqb4nQlUD0WNRM3TVjGWGkgWRV0K3jjZJLy1tS+EjgCUDkVdEpxsApQXRY1MLT94VegIQOFQ1MiQaY3PDx0CKByKuiDmj94YOkJCGLUCdIqiLogd6hclB1QTRY3ELbJ1YogekByKuhTyVYpcHApIFkVdeK5VvV8JHQJAiijqEljY+2DoCB0ZGnt76AhAoVDUyJhpydgnQocACoWiLoDyXTWP1Q7oBO+YAuCqeUC1UdRIxareLytvo1GAoqKoC81V04HQIZoq2gFOIM8o6oLbXrsmdAQAKaOoEcTQ5pHQEYDCoKhzrjwXY5rItOSOLaFDAIVBUeccF2MCQFEjNb06JEZ+AN2jqJGanbWrQ0cASoGiLizXidofOgSADFDUBba19vHQEbqyfGhb6AhAIVDUOVb2q8yt2fB06AhAIVDUObZk7JNixAcAijrXil/S87RVjPwAukNRF1Yxym9t7QuhIwCFR1EXkmuRrQ8dAkBGKOqCKssHyF7x7z8OHQHIPYo6p8o+4mPcAz9/PnQEIPco6pxaMvbXKsPBRADdo6iRgcMqysFPII8ii9rMvmZmu83skSwCIYrLNBY6REd21f4ydASg0OJsUf+XpAUp50AHnqpdFTpCoubffH/oCECuRRa1u/9QEkd8MrT8YLmKOMqO3b8LHQHINfZR59Aav0QcSAQwLrGiNrPFZjZsZsN79uxJ6mkBoPISK2p3X+3ug+4+2NfXl9TT4ijFHD2xyNapqNmB0Nj1USjFPXU86kxKDigCrcUZnne7pB9LeqOZPWNmH00/VnVFHUgsy6njU3FAEWitN2oGd/9wFkFQx4FEAFOx66NQ2McLVBFFXRjF3T89jgOKwLGhqAuk6Puno/LPuf6ejJIAxUJR58j80RtDRwhq38HDoSMAuURR58gO9YsDiQCmoqiRqZoOiP3UQGco6pxo/4kurnP0dGZZ0rS9dk3b6Wct/V5GSYDioKhzYsnYJ9Vut8f62rLswgTEtjZwNIo6N9g3DaA5iroQyrWdeap+3XY6n0wOTEZR50D763u4VvV+JbMsWdhYu7btdD6ZHJiMos6BqOt7LOx9MLswAHKHogaAnKOoAxvaPBI6QhAnzuhpO/3CG4p9XRMgSRR1YH93xxa13u3hmqetGabJztbPtf9g++f2H8ooCZB/FHVgUeM51ta+kEkOAPlFUSO3qrpbCJiKog6o/X5YjxxvXHSL5va3nb7kji3ZBAFyjqIOKGo/bNR446JbufC80BGAQqCoA+Hsu7rjIs6c58MEAIo6mPZn35V3tMdUN//ZW9pO58MEAIo6t6oy2mPh+adHzsOYalQdRR1A9G6Pcl2EKcq8N5zSdjpjqlF1FHUAUbs9ynYRpihrP3ZR5DwM1UOVUdQZi3NwjIswHY2heqgyijpDQ5tHIg6OlecjtzoVtftDkpYPbcsgCZA/FHWGrrszumiq8pFbU8XZ/bFmQzV/iQEUdUaWD23T7w6xNd1O1JmKkjTAh9+igijqDCwf2hZra7CqW9Pj4p6pePYyyhrVQlFnILqkq3OCS5RVf/6WyHnGnDM7US3mnvyY3cHBQR8eHk78eYtmaPNIzNEKrl21K9KOUxhzRr+qfZql9p/M7lpk67Ryxq2dPfmK33YTDUiNmW1y98Fm03qzDlMV5153t0YPx/slWPar5HVqa+3jGhhdGzGXaY1foqdGX1uZszhRXez6SNjyoW0aWPq92CUtlf8qecei/ssrahmaHtAcDYyu1fzRG7OIBQTBFnVC5t98v3bs/l3Hj9t102XSiuTzFN3G2rU6e/Q/Nabpar8LpD5th/pf3gqfp61sZaNUYhW1mS2Q9CVJPZJucfebUk2VU0ObR7TiO49q74GXun6uWo9p+w2XJpCqvHbWro65v1qTpo9vZU+1yNZpZbIRgUxEHkw0sx5JP5M0X9Izkn4q6cPu/lirxxzLwcShzSP64g+e0P/uPaDfP2mmPv3uN7a9stryoW26feMvddhdPWaa+/qTtes3BzSy98BR854wvUcfuOB03bd9T9PpJsmb/Jl9vA7oJfXoJU2fMnc3XCdqv7bWPt7l81THwOhtqm8jdL/su3mOHpOm7tFqdp9JmtZjOtSYcJxJR5q8zU6dNX3SBadM0hVz+zV45in64g+e0MjeA+ox02F3zZx2nA68dGTS48fX67sefvbljYeTj5+m69/7psirEi4f2qa1G55+ea2f3mM6YUav9r74Uqz3n9T5e7bT+aMk/XzdvFYSWdodTIxT1BdJWuHu7258v0yS3L3lTsFOi3po84iWfXubDrz0ygkhM6f16MY/Pa/pDxt3XHL+uKQj2lW7MnSQwhkYXaN6lXVb1vnXc5zpcLNmj2laj+mLH3pzy6KI8/5p9/6TOn/Pdjp/lKSfr5vXSipLt0X9IUkL3P2axvdXSrrQ3T/V6jGdFvW8m+5tsaV7RDNU31LwCW/Qg5qmYr1h68u4pgPaXrsmcJbiemWftVSs///smY5ophpb69NPmDTtxbZnyE58Dun46T1Np7146HDTQ72tHtPp/FGSfr5uXqvV9NNPmqkHll4c+3UyGZ5nZoslLW58+4KZPRH3sdNfe/ZbW0079Kudv5Amj19rN39eHfrVzk1S7utltpTnsYIflCRNP/UNF8gs54syvPF1bqpO3j8TnmPSuhHxnj3qdTudP0oHz9f1Oh31Wq2mPyvJlnX0s53ZakKcoh6R9LoJ35/RuG8Sd18taXUHoWIxs+FWv2XyqoiZpWLmJnM2iphZKm7uqeKMo/6ppHPM7Cwzmy7pcknfSTcWAGBc5Ba1u4+Z2ack/UD1Q+9fc/dHU08GAJAUcx+1u98t6e6Us7SS+O6UDBQxs1TM3GTORhEzS8XNPUkqF2UCACSHa30AQM4FLWozW2BmT5jZTjNb2mT6R8xsj5ltaXxdM2HaVWa2o/F1VY4y//OEvD8zs70Tph2eMC2zA7Jm9jUz221mj7SYbmb2L42faauZXTBhWqjlHJX5ikbWbWb2oJm9ecK0XY37t5hZZtfbjZH5nWb22wnrwGcnTGu7XgXM/OkJeR9prMOnNKaFWs6vM7P7zOwxM3vUzI66qlke1+muuHuQL9UPTP5c0uslTZf0sKQ/nDLPRyT9a5PHniLpyca/Jzdun5yHzFPm/xvVD76Of/9CoGX9x5IukPRIi+mXSvq+6sO850raGHI5x8z89vEskv5kPHPj+12SZudwOb9T0l3drldZZp4y73sl3ZuD5XyapAsat2epfomLqd2Ru3W6m6+QW9Rvk7TT3Z9090OSviHp/TEf+25J6939eXf/P0nrJS1IKedEnWb+sKTbM8jVlrv/UNLzbWZ5v6TbvG6DpJPM7DSFW86Rmd39wUYmSdqg+vj+oGIs51a6eS90pcPMeVmfn3X3hxq390t6XNLUc7Vzt053I2RRny7plxO+f0ZHL2xJ+mDjT5dvmtn4iTdxH5u02K9rZmdKOkvSvRPurpnZsJltMLOFqaXsXKufK9Ry7tRHVd96GueS1pnZpsYZs3lykZk9bGbfN7M3Ne7L/XI2s+NVL7RvTbg7+HI2swFJ50vaOGVS0dfpSfJ+PervSrrd3Q+a2V9JulVS/JPnw7pc0jfdfeKFFc509xEze72ke81sm7v/PFC+UjCzd6le1O+YcPc7Gsv5NZLWm9n2xpZjaA+pvg68YGaXShqSdE7YSLG9V9ID7j5x6zvocjazV6n+i2OJu+/L6nVDCLlFHXlqurv/xt0PNr69RdJb4z42JZ287uWa8meiu480/n1S0v2qbwnkQaufK9RyjsXM5qi+Xrzf3X8zfv+E5bxb0p2q71oIzt33ufsLjdt3S5pmZrOV8+Xc0G59znw5m9k01Ut6rbt/u8kshVynWwq1c1z1rfknVd89MH4A5U1T5jltwu0PSNrgrxwQeEr1gwEnN26fkofMjfnOVf1Ai02472RJMxq3Z0vaoYwOGDVec0CtD3JdpskHXn4ScjnHzNwvaaekt0+5/wRJsybcflD1qz/mIfNrx9cJ1Uvt6cYyj7VehcjcmP5q1fdjn5CH5dxYZrdJWtVmnlyu08f6FWzXh7c4Nd3MPi9p2N2/I+lvzex9ksZUX1E+0njs82b2T6pfh0SSPu+T/yQLmVmqb318wxtrRsMfSPo3Mzui+l8yN3mbD19IkpndrvqIg9lm9oyk6yVNa/xMX1X9rNNLVS++FyVd3ZgWZDnHzPxZSb8n6StWv5DemNcvvnOqpDsb9/VK+rq735OTzB+S9AkzG5N0QNLljXUk2GUaYmSW6htJ69x94mfNBVvOkuZJulLSNjPb0rjvH1X/5Z3bdbobnJkIADnHmYkAkHMUNQDkHEUNADlHUQNAzlHUAJBzFDUA5BxFDQA5R1EDQM79P0NFQ7xhBqOmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_target = sorted(target)\n",
    "\n",
    "fit = stats.norm.pdf(sorted_target, np.mean(sorted_target), np.std(sorted_target))  #this is a fitting indeed\n",
    "\n",
    "pl.plot(sorted_target,fit,'-o')\n",
    "\n",
    "pl.hist(sorted_target,density=True)      #use this to draw histogram of your data\n",
    "\n",
    "pl.show()                   #use may also need add this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(target))\n",
    "print(type(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6814339011044555 2.158060831840756 0.4766269307363007\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.765222</td>\n",
       "      <td>-77.153948</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.354421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-267.438456</td>\n",
       "      <td>0.228461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741254</td>\n",
       "      <td>-82.376508</td>\n",
       "      <td>52.134155</td>\n",
       "      <td>6.632972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-145.653123</td>\n",
       "      <td>0.176235</td>\n",
       "      <td>0.999068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.917195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-19.269571</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.741254</td>\n",
       "      <td>-282.908684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-286.708028</td>\n",
       "      <td>-1.829087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741254</td>\n",
       "      <td>-74.895327</td>\n",
       "      <td>53.960325</td>\n",
       "      <td>7.737497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-138.004542</td>\n",
       "      <td>0.251047</td>\n",
       "      <td>0.999068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.070974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.697913</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.741254</td>\n",
       "      <td>438.066444</td>\n",
       "      <td>82.524541</td>\n",
       "      <td>0.713415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-259.859071</td>\n",
       "      <td>5.380664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741254</td>\n",
       "      <td>-52.952915</td>\n",
       "      <td>58.911769</td>\n",
       "      <td>8.575745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-130.137081</td>\n",
       "      <td>0.470471</td>\n",
       "      <td>0.999068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.951560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>178.444487</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.741254</td>\n",
       "      <td>12.658751</td>\n",
       "      <td>92.757045</td>\n",
       "      <td>5.757982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-200.377576</td>\n",
       "      <td>1.126588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741254</td>\n",
       "      <td>-69.991872</td>\n",
       "      <td>54.050572</td>\n",
       "      <td>7.763921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-107.700809</td>\n",
       "      <td>0.300081</td>\n",
       "      <td>0.999068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.943828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>114.626319</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.741254</td>\n",
       "      <td>-91.291578</td>\n",
       "      <td>50.003979</td>\n",
       "      <td>5.468393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-171.720996</td>\n",
       "      <td>0.087084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741254</td>\n",
       "      <td>-71.095124</td>\n",
       "      <td>53.741353</td>\n",
       "      <td>7.098725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-79.085860</td>\n",
       "      <td>0.289049</td>\n",
       "      <td>0.999068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.871262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10154</th>\n",
       "      <td>0.985976</td>\n",
       "      <td>0.894567</td>\n",
       "      <td>1.006336</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.793062</td>\n",
       "      <td>1.001173</td>\n",
       "      <td>0.922541</td>\n",
       "      <td>0.827488</td>\n",
       "      <td>891.495321</td>\n",
       "      <td>0.914848</td>\n",
       "      <td>...</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>-2.084158</td>\n",
       "      <td>0.995109</td>\n",
       "      <td>0.593247</td>\n",
       "      <td>0.370577</td>\n",
       "      <td>861.940620</td>\n",
       "      <td>1.166642</td>\n",
       "      <td>1.000287</td>\n",
       "      <td>47.873165</td>\n",
       "      <td>0.913916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10155</th>\n",
       "      <td>0.998621</td>\n",
       "      <td>0.894783</td>\n",
       "      <td>1.004395</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>9.737954</td>\n",
       "      <td>1.000621</td>\n",
       "      <td>0.507849</td>\n",
       "      <td>0.806466</td>\n",
       "      <td>866.491970</td>\n",
       "      <td>0.896696</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>-6.848505</td>\n",
       "      <td>0.989094</td>\n",
       "      <td>0.076856</td>\n",
       "      <td>0.260252</td>\n",
       "      <td>855.841752</td>\n",
       "      <td>1.281253</td>\n",
       "      <td>0.998892</td>\n",
       "      <td>8.192992</td>\n",
       "      <td>1.018863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10156</th>\n",
       "      <td>0.997993</td>\n",
       "      <td>0.890861</td>\n",
       "      <td>0.995688</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>-6.024870</td>\n",
       "      <td>0.996708</td>\n",
       "      <td>0.294143</td>\n",
       "      <td>0.556294</td>\n",
       "      <td>862.976930</td>\n",
       "      <td>1.130891</td>\n",
       "      <td>...</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.070078</td>\n",
       "      <td>0.991300</td>\n",
       "      <td>0.680244</td>\n",
       "      <td>0.394779</td>\n",
       "      <td>854.548326</td>\n",
       "      <td>1.014084</td>\n",
       "      <td>0.992495</td>\n",
       "      <td>47.559919</td>\n",
       "      <td>1.013033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10157</th>\n",
       "      <td>1.000098</td>\n",
       "      <td>0.891527</td>\n",
       "      <td>0.998571</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>3.550548</td>\n",
       "      <td>0.998021</td>\n",
       "      <td>0.630335</td>\n",
       "      <td>0.421817</td>\n",
       "      <td>861.631161</td>\n",
       "      <td>1.245402</td>\n",
       "      <td>...</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.204299</td>\n",
       "      <td>0.992909</td>\n",
       "      <td>0.627318</td>\n",
       "      <td>0.450706</td>\n",
       "      <td>852.628693</td>\n",
       "      <td>1.067194</td>\n",
       "      <td>0.996860</td>\n",
       "      <td>53.522837</td>\n",
       "      <td>0.936996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10158</th>\n",
       "      <td>1.000439</td>\n",
       "      <td>0.890970</td>\n",
       "      <td>0.994929</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>7.060167</td>\n",
       "      <td>0.996308</td>\n",
       "      <td>0.442653</td>\n",
       "      <td>0.374628</td>\n",
       "      <td>862.309749</td>\n",
       "      <td>1.372337</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-2.001136</td>\n",
       "      <td>0.988768</td>\n",
       "      <td>0.177002</td>\n",
       "      <td>0.506900</td>\n",
       "      <td>851.219888</td>\n",
       "      <td>1.114346</td>\n",
       "      <td>0.989711</td>\n",
       "      <td>33.360103</td>\n",
       "      <td>1.011907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10159 rows Ã— 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1         2          3           4           5  \\\n",
       "0      0.000000    0.000000 -1.000000   0.765222  -77.153948  100.000000   \n",
       "1      0.000000  -19.269571 -1.000000   0.741254 -282.908684    0.000000   \n",
       "2      0.000000   53.697913 -1.000000   0.741254  438.066444   82.524541   \n",
       "3      0.000000  178.444487 -1.000000   0.741254   12.658751   92.757045   \n",
       "4      0.000000  114.626319 -1.000000   0.741254  -91.291578   50.003979   \n",
       "...         ...         ...       ...        ...         ...         ...   \n",
       "10154  0.985976    0.894567  1.006336  48.000000    2.793062    1.001173   \n",
       "10155  0.998621    0.894783  1.004395  44.000000    9.737954    1.000621   \n",
       "10156  0.997993    0.890861  0.995688  40.000000   -6.024870    0.996708   \n",
       "10157  1.000098    0.891527  0.998571  36.000000    3.550548    0.998021   \n",
       "10158  1.000439    0.890970  0.994929  32.000000    7.060167    0.996308   \n",
       "\n",
       "              6         7           8         9  ...         75         76  \\\n",
       "0      0.354421  0.000000 -267.438456  0.228461  ...   0.741254 -82.376508   \n",
       "1     -0.001874  0.000000 -286.708028 -1.829087  ...   0.741254 -74.895327   \n",
       "2      0.713415  0.000000 -259.859071  5.380664  ...   0.741254 -52.952915   \n",
       "3      5.757982  0.000000 -200.377576  1.126588  ...   0.741254 -69.991872   \n",
       "4      5.468393  0.000000 -171.720996  0.087084  ...   0.741254 -71.095124   \n",
       "...         ...       ...         ...       ...  ...        ...        ...   \n",
       "10154  0.922541  0.827488  891.495321  0.914848  ...  24.000000  -2.084158   \n",
       "10155  0.507849  0.806466  866.491970  0.896696  ...  20.000000  -6.848505   \n",
       "10156  0.294143  0.556294  862.976930  1.130891  ...  16.000000   0.070078   \n",
       "10157  0.630335  0.421817  861.631161  1.245402  ...  12.000000   1.204299   \n",
       "10158  0.442653  0.374628  862.309749  1.372337  ...   8.000000  -2.001136   \n",
       "\n",
       "              77        78        79          80        81        82  \\\n",
       "0      52.134155  6.632972  0.000000 -145.653123  0.176235  0.999068   \n",
       "1      53.960325  7.737497  0.000000 -138.004542  0.251047  0.999068   \n",
       "2      58.911769  8.575745  0.000000 -130.137081  0.470471  0.999068   \n",
       "3      54.050572  7.763921  0.000000 -107.700809  0.300081  0.999068   \n",
       "4      53.741353  7.098725  0.000000  -79.085860  0.289049  0.999068   \n",
       "...          ...       ...       ...         ...       ...       ...   \n",
       "10154   0.995109  0.593247  0.370577  861.940620  1.166642  1.000287   \n",
       "10155   0.989094  0.076856  0.260252  855.841752  1.281253  0.998892   \n",
       "10156   0.991300  0.680244  0.394779  854.548326  1.014084  0.992495   \n",
       "10157   0.992909  0.627318  0.450706  852.628693  1.067194  0.996860   \n",
       "10158   0.988768  0.177002  0.506900  851.219888  1.114346  0.989711   \n",
       "\n",
       "              83        84  \n",
       "0       0.000000  0.917195  \n",
       "1       0.000000  1.070974  \n",
       "2       0.000000  0.951560  \n",
       "3       0.000000  0.943828  \n",
       "4       0.000000  0.871262  \n",
       "...          ...       ...  \n",
       "10154  47.873165  0.913916  \n",
       "10155   8.192992  1.018863  \n",
       "10156  47.559919  1.013033  \n",
       "10157  53.522837  0.936996  \n",
       "10158  33.360103  1.011907  \n",
       "\n",
       "[10159 rows x 85 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_max = max(target)\n",
    "data_min = min(target)\n",
    "data_range = data_max - data_min\n",
    "print(data_range, data_max, data_min)\n",
    "\n",
    "df = data.iloc[:,1:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"data/all_data.csv\")\n",
    "target = data.iloc[:,85]\n",
    "features = data.iloc[:,1:85]\n",
    "\n",
    "# 60-20-20\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
      "[CV] END .......................criterion=mse, splitter=best; total time=   0.7s\n",
      "[CV] END .......................criterion=mse, splitter=best; total time=   0.6s\n",
      "[CV] END .....................criterion=mse, splitter=random; total time=   0.0s\n",
      "[CV] END .....................criterion=mse, splitter=random; total time=   0.0s\n",
      "[CV] END ..............criterion=friedman_mse, splitter=best; total time=   0.7s\n",
      "[CV] END ..............criterion=friedman_mse, splitter=best; total time=   0.6s\n",
      "[CV] END ............criterion=friedman_mse, splitter=random; total time=   0.0s\n",
      "[CV] END ............criterion=friedman_mse, splitter=random; total time=   0.0s\n",
      "[CV] END .......................criterion=mae, splitter=best; total time=  31.4s\n",
      "[CV] END .......................criterion=mae, splitter=best; total time=  16.9s\n",
      "[CV] END .....................criterion=mae, splitter=random; total time=   7.0s\n",
      "[CV] END .....................criterion=mae, splitter=random; total time=   3.9s\n",
      "[CV] END ...................criterion=poisson, splitter=best; total time=   4.5s\n",
      "[CV] END ...................criterion=poisson, splitter=best; total time=   4.2s\n",
      "[CV] END .................criterion=poisson, splitter=random; total time=   0.1s\n",
      "[CV] END .................criterion=poisson, splitter=random; total time=   0.1s\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This DecisionTreeRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20980/1057230636.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \"\"\"\n\u001b[1;32m--> 441\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This DecisionTreeRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\"criterion\": [\"mse\", \"friedman_mse\", \"mae\", \"poisson\"],\n",
    "          \"splitter\": [\"best\", \"random\"]\n",
    "}\n",
    "\n",
    "regressor = DecisionTreeRegressor()\n",
    "\n",
    "clf = GridSearchCV(regressor, params, verbose=2, cv=2)\n",
    "\n",
    "# regressor = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "preds = regressor.predict(X_test)\n",
    "mean_squared_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17012/626443123.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.01111969, 0.87776167, 0.93893613, ..., 0.9894168 , 1.        ,\n",
       "       0.94943662])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(preds))\n",
    "print(type(y_test.to_numpy()))\n",
    "\n",
    "y_test = y_test.to_numpy()\n",
    "preds\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4881889763779528"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_yon = []\n",
    "gercek_yon = []\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    if preds[i] < 1:\n",
    "        pred_yon.append(\"neg\")\n",
    "    else:\n",
    "        pred_yon.append(\"pos\")\n",
    "\n",
    "    if y_test[i] < 1:\n",
    "        gercek_yon.append(\"neg\")\n",
    "    else:\n",
    "        gercek_yon.append(\"pos\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(pred_yon, gercek_yon)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "410307664c3b7ae8cf4ec4c8c111266d5283fec415142dc2cbd04795b4f02a6d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
